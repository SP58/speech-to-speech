{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nlpgridio3/data/awadhawan/s2st/translatotron2/tenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import torch\n",
    "# from balacoon_tts import TTS\n",
    "import time\n",
    "import threading\n",
    "from TTS.api import TTS\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Balacoon TTS\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tts \u001b[39m=\u001b[39m TTS(\u001b[39m\"\u001b[39m\u001b[39mmodels/en_us_hifi92_e2ept.addon\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m supported_speakers \u001b[39m=\u001b[39m tts\u001b[39m.\u001b[39mget_speakers()\n\u001b[1;32m      4\u001b[0m speaker \u001b[39m=\u001b[39m supported_speakers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m supported_speakers \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TTS' is not defined"
     ]
    }
   ],
   "source": [
    "# Balacoon TTS\n",
    "tts = TTS(\"models/en_us_hifi92_e2ept.addon\")\n",
    "supported_speakers = tts.get_speakers()\n",
    "speaker = supported_speakers[-1] if supported_speakers else \"\"\n",
    "print(supported_speakers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home1/a/anshulw/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425M/425M [00:24<00:00, 17.3MiB/s] \n",
      "/mnt/nlpgridio3/data/awadhawan/s2st/translatotron2/tenv/lib/python3.9/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CC BY-NC-ND 4.0\n",
      " > Check https://creativecommons.org/licenses/by-nc-nd/4.0/ for more info.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n"
     ]
    }
   ],
   "source": [
    "#Coqui TTS\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=True, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eleven Labs\n",
    "url = \"https://api.elevenlabs.io/v1/text-to-speech/TxGEqnHWrfWFTfGW9XjX\"\n",
    "headers = {\n",
    "    \"xi-api-key\": \"ff79eb4ad43bb12b04a3968a5b92125b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"A muffin is an individually portioned baked product, however the term can refer to one of two distinct items: a part-raised flatbread that is baked and then cooked on a griddle, or a quickbread that is chemically leavened and then baked in a mold.\"\n",
    "text_small = \"Muffin is a baked item, either a flatbread cooked on griddle or a quickbread leavened chemically and baked in a mold.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_write(sentence):\n",
    "    for word in sentence.split():\n",
    "        with open(\"streaming_input.txt\", \"a\") as file:\n",
    "            file.write(word+\" \")\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_thread = threading.Thread(target=streaming_write, args = (text,) )\n",
    "write_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_thread = threading.Thread(target=streaming_write, args = (text_small,) )\n",
    "write_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_audio(chunk, name):\n",
    "    # samples = tts.synthesize(chunk, speaker)\n",
    "    # with wave.open(\"outputs/example\"+ str(name) +\".wav\", \"w\") as fp:\n",
    "    #     fp.setparams((1, 2, 24000, len(samples), \"NONE\", \"NONE\"))\n",
    "    #     fp.writeframes(samples)\n",
    "    \n",
    "    # TODO: 16k sample rate\n",
    "    # tts.tts_to_file(chunk, speaker_wav=\"inputs/CommonVoiceES.wav\", language=\"en\", file_path=\"outputs/example\"+ str(name) +\".wav\")\n",
    "    # tts.tts_to_file(chunk, speaker=tts.speakers[0], language=\"en\", file_path=\"outputs/example\"+ str(name) +\".wav\")\n",
    "    data = {\n",
    "        \"text\": chunk,\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0,\n",
    "            \"similarity_boost\": 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"outputs/example\"+ str(name) +\".mp3\", 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def streamingTTS():\n",
    "    content=\"\"\n",
    "    while True:\n",
    "        with open(\"streaming_input.txt\", \"r\") as file:\n",
    "            new_content = file.read()\n",
    "            print(len(content), len(new_content))\n",
    "            if len(new_content) > len(content):\n",
    "                convert_to_audio(new_content[len(content):], len(new_content))\n",
    "                content = new_content\n",
    "            else:\n",
    "                break\n",
    "        time.sleep(1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 64\n",
      "64 118\n",
      "118 118\n"
     ]
    }
   ],
   "source": [
    "tts_thread = threading.Thread(target=streamingTTS)\n",
    "tts_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
